{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Dependencies and Shared Objects\n",
    "\n",
    "Execute this first to get all of the imports, env variables, and shared objects loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "from typing import List, Dict\n",
    "import tiktoken\n",
    "\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_community.document_loaders import (\n",
    "    # UnstructuredExcelLoader,\n",
    "    # UnstructuredHTMLLoader,\n",
    "    # UnstructuredPDFLoader,\n",
    "    UnstructuredFileLoader,\n",
    ")\n",
    "from unstructured.cleaners.core import (\n",
    "    clean_extra_whitespace,\n",
    "    clean_non_ascii_chars,\n",
    "    clean_bullets,\n",
    "    group_broken_paragraphs,\n",
    "    auto_paragraph_grouper,\n",
    "    replace_unicode_quotes,\n",
    "    clean_dashes,\n",
    "    replace_mime_encodings,\n",
    ")\n",
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "from settings import settings\n",
    "\n",
    "\n",
    "OPENAI_API_KEY = settings.openai_api_key\n",
    "EMBEDDING_MODEL = settings.embedding_model\n",
    "OPENAPI_BASE_URL = settings.openai_base_url\n",
    "PRIMARY_MODEL = settings.primary_model\n",
    "SECONDARY_MODEL = settings.secondary_model\n",
    "INPUT_PATH = settings.input_path\n",
    "OUTPUT_PATH = settings.output_path\n",
    "\n",
    "\n",
    "def num_tokens_from_string(string: str) -> int:\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "\n",
    "llm_1 = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    max_tokens=1000,\n",
    "    verbose=True,\n",
    "    model_name=PRIMARY_MODEL,\n",
    "    model_kwargs={\"top_p\": 0, \"frequency_penalty\": 0, \"presence_penalty\": 0},\n",
    ")\n",
    "\n",
    "llm_1_json = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    max_tokens=1000,\n",
    "    model_name=PRIMARY_MODEL,\n",
    "    verbose=True,\n",
    "    model_kwargs={\n",
    "        \"top_p\": 0,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"presence_penalty\": 0,\n",
    "        \"response_format\": {\"type\": \"json_object\"},\n",
    "    },\n",
    ")\n",
    "\n",
    "llm_2 = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    max_tokens=1000,\n",
    "    verbose=True,\n",
    "    model_name=SECONDARY_MODEL,\n",
    "    model_kwargs={\"top_p\": 0, \"frequency_penalty\": 0, \"presence_penalty\": 0},\n",
    ")\n",
    "\n",
    "llm_2_json = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    max_tokens=1000,\n",
    "    model_name=\"gpt-4-turbo-preview\",\n",
    "    verbose=True,\n",
    "    model_kwargs={\n",
    "        \"top_p\": 0,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"presence_penalty\": 0,\n",
    "        \"response_format\": {\"type\": \"json_object\"},\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to ingest any file type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(filename: str):\n",
    "    input_file = os.path.join(INPUT_PATH, filename)\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    loader = UnstructuredFileLoader(\n",
    "        input_file,\n",
    "        post_processors=[\n",
    "            # group_bullet_paragraph,\n",
    "            clean_extra_whitespace,\n",
    "            group_broken_paragraphs,\n",
    "            # auto_paragraph_grouper,\n",
    "            clean_bullets,\n",
    "            clean_dashes,\n",
    "            clean_non_ascii_chars,\n",
    "            replace_unicode_quotes,\n",
    "            replace_mime_encodings,\n",
    "            # group_bullet_paragraph,\n",
    "            # new_line_grouper,\n",
    "            # index_adjustment_after_clean_extra_whitespace,\n",
    "            # clean_ordered_bullets,\n",
    "            # clean_ligatures,\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    documents: List[Document] = loader.load()\n",
    "\n",
    "    end_time = datetime.now()\n",
    "    elapsed_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "    char_count = 0\n",
    "    for doc in documents:\n",
    "        char_count += len(doc.page_content)\n",
    "\n",
    "    logger.info(f\"{input_file=}, {len(documents)=}, {char_count=}, {elapsed_time=} seconds\")\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract text from all documents\n",
    "\n",
    "loop through files of different types and extract their text forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 13:52:37,832 - INFO - input_file='data/input/example.xls', len(documents)=1, char_count=1226, elapsed_time=0.180822 seconds\n",
      "2024-03-27 13:52:37,834 - INFO - pikepdf C++ to Python logger bridge initialized\n",
      "2024-03-27 13:52:49,722 - INFO - input_file='data/input/prospectus.pdf', len(documents)=1, char_count=541751, elapsed_time=11.889467 seconds\n",
      "2024-03-27 13:52:49,758 - INFO - input_file='data/input/sample.xlsx', len(documents)=1, char_count=3182, elapsed_time=0.035013 seconds\n"
     ]
    }
   ],
   "source": [
    "filenames = [\"example.xls\", \"prospectus.pdf\", \"sample.xlsx\"]\n",
    "\n",
    "all_documents = dict()\n",
    "\n",
    "for filename in filenames:\n",
    "\n",
    "    all_documents[filename] = {\"documents\": extract_text(filename)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the files and create collection for each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 13:52:53,241 - INFO - filename='example.xls', len(file_docs)=1, len(split_docs)=1, elapsed_time=0.000295 seconds\n",
      "2024-03-27 13:52:53,246 - INFO - filename='prospectus.pdf', len(file_docs)=1, len(split_docs)=172, elapsed_time=0.004776 seconds\n",
      "2024-03-27 13:52:53,246 - INFO - filename='sample.xlsx', len(file_docs)=1, len(split_docs)=1, elapsed_time=0.005251 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "text_splitter2 = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\"],\n",
    "    chunk_size=3500,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for filename in all_documents.keys():\n",
    "\n",
    "    file_data: Dict = all_documents[filename]\n",
    "    file_docs = file_data.get(\"documents\")\n",
    "    split_docs = text_splitter2.split_documents(documents=file_docs)\n",
    "    all_documents[filename].update({\"split_docs\": split_docs})\n",
    "\n",
    "    end_time = datetime.now()\n",
    "    elapsed_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "    logger.info(f\"{filename=}, {len(file_docs)=}, {len(split_docs)=}, {elapsed_time=} seconds\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize chunk length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "\n",
    "filename = \"prospectus.pdf\"\n",
    "\n",
    "add_document_docs = list()\n",
    "for filename in all_documents.keys():\n",
    "    file_data: Dict = all_documents.get(filename)\n",
    "    split_docs = file_data.get(\"split_docs\")\n",
    "    logger.info(split_docs)\n",
    "    add_document_docs += split_docs\n",
    "\n",
    "\n",
    "counts = [\n",
    "    num_tokens_from_string(doc.page_content)\n",
    "    for doc in add_document_docs\n",
    "]\n",
    "\n",
    "\n",
    "pyplot.figure(figsize=(10, 6))\n",
    "pyplot.hist(counts, bins=30, color=\"blue\", edgecolor=\"black\", alpha=0.7)\n",
    "pyplot.title(\"Histogram of Token Cnts\")\n",
    "pyplot.xlabel(\"Token Counts\")\n",
    "pyplot.ylabel(\"Frequency\")\n",
    "pyplot.grid(axis=\"y\", alpha=0.75)\n",
    "pyplot.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the vectorstore\n",
    "\n",
    "Using qdrant here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 13:53:09,969 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-27 13:53:11,774 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-27 13:53:14,236 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-27 13:53:16,428 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores.qdrant import Qdrant\n",
    "\n",
    "\n",
    "vectorstore = Qdrant.from_documents(\n",
    "    add_document_docs,\n",
    "    embedding=embedding_model,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"multiple-files\",\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple retriever\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 13:53:36,111 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Online Instruction Page\\n\\nSample Data for Excel\\n\\nOffice Supply Sales Data\\n\\nRelated tutorials\\n\\nMore Excel Sample Files\\n\\nNamed Excel Tables\\n\\nData Entry Tips\\n\\nNotes\\n\\nSalesOrders sheet has office supply sales data for a fictional company \\n\\n Each row represents an order. \\n\\n The Total column could be changed to a formula, to multiply the Units and Cost columns.\\n\\nOrderDate Region Rep Item Units Unit Cost Total 2021 01 06 00:00:00 East Jones Pencil 95 1.99 189.05 2021 01 23 00:00:00 Central Kivell Binder 50 19.99 999.5 2021 02 09 00:00:00 Central Jardine Pencil 36 4.99 179.64 2021 02 26 00:00:00 Central Gill Pen 27 19.99 539.73 2021 03 15 00:00:00 West Sorvino Pencil 56 2.99 167.44 2021 04 01 00:00:00 East Jones Binder 60 4.99 299.4 2021 04 18 00:00:00 Central Andrews Pencil 75 1.99 149.25 2021 05 05 00:00:00 Central Jardine Pencil 90 4.99 449.1 2021 05 22 00:00:00 West Thompson Pencil 32 1.99 63.68 2021 06 08 00:00:00 East Jones Binder 60 8.99 539.4 2021 06 25 00:00:00 Central Morgan Pencil 90 4.99 449.1 2021 07 12 00:00:00 East Howard Binder 29 1.99 57.71 2021 07 29 00:00:00 East Parent Binder 81 19.99 1619.19 2021 08 15 00:00:00 East Jones Pencil 35 4.99 174.65 2021 09 01 00:00:00 Central Smith Desk 2 125 250 2021 09 18 00:00:00 East Jones Pen Set 16 15.99 255.84 2021 10 05 00:00:00 Central Morgan Binder 28 8.99 251.72 2021 10 22 00:00:00 East Jones Pen 64 8.99 575.36 2021 11 08 00:00:00 East Parent Pen 15 19.99 299.85 2021 11 25 00:00:00 Central Kivell Pen Set 96 4.99 479.04 2021 12 12 00:00:00 Central Smith Pencil 67 1.29 86.43 2021 12 29 00:00:00 East Parent Pen Set 74 15.99 1183.26 2022 01 15 00:00:00 Central Gill Binder 46 8.99 413.54 2022 02 01 00:00:00 Central Smith Binder 87 15 1305 2022 02 18 00:00:00 East Jones Binder 4 4.99 19.96 2022 03 07 00:00:00 West Sorvino Binder 7 19.99 139.93 2022 03 24 00:00:00 Central Jardine Pen Set 50 4.99 249.5 2022 04 10 00:00:00 Central Andrews Pencil 66 1.99 131.34 2022 04 27 00:00:00 East Howard Pen 96 4.99 479.04 2022 05 14 00:00:00 Central Gill Pencil 53 1.29 68.37 2022 05 31 00:00:00 Central Gill Binder 80 8.99 719.2 2022 06 17 00:00:00 Central Kivell Desk 5 125 625 2022 07 04 00:00:00 East Jones Pen Set 62 4.99 309.38 2022 07 21 00:00:00 Central Morgan Pen Set 55 12.49 686.95 2022 08 07 00:00:00 Central Kivell Pen Set 42 23.95 1005.9 2022 08 24 00:00:00 West Sorvino Desk 3 275 825 2022 09 10 00:00:00 Central Gill Pencil 7 1.29 9.03 2022 09 27 00:00:00 West Sorvino Pen 76 1.99 151.24 2022 10 14 00:00:00 West Thompson Binder 57 19.99 1139.43 2022 10 31 00:00:00 Central Andrews Pencil 14 1.29 18.06 2022 11 17 00:00:00 Central Jardine Binder 11 4.99 54.89 2022 12 04 00:00:00 Central Jardine Binder 94 19.99 1879.06 2022 12 21 00:00:00 Central Andrews Binder 28 4.99 139.72\\n\\nContextures Sites & News\\n\\nContextures Excel Tips Website Hundreds of tutorials, tips and sample files Contextures Excel Blog Excel tutorials and tips, with comments and questions Excel Pivot Tables Blog Pivot table tutorials and tips, with comments and questions Contextures Excel Newsletter Get emails with Excel tips, links, and news\\n\\nExcel Products\\n\\nContextures Recommends Excel tools and training, recommended by Debra', metadata={'source': 'data/input/sample.xlsx', '_id': 'e54c7a9691614723959d7dfc8ac11b88', '_collection_name': 'multiple-files'}),\n",
       " Document(page_content='The Representative of the Noteholders may also, whenever it considers to be expedient and in the interests of the Noteholders, whether by power of attorney or otherwise, delegate to any Person(s) all or any of the powers, authorities and discretion vested in it as aforesaid. Any such delegation may be made upon such terms and conditions and subject to such regulations (including power to sub delegate) as the Representative of the Noteholders may think fit, provided that: (a) the Representative of the Noteholders shall use all reasonable care and skill in the selection of the sub agent, sub contractor or representative which must fall within one of the categories set forth in Article 25 (Appointment, Removal and Remuneration) herein; and (b) the sub agent, sub contractor or representative shall undertake to perform the obligations of the Representative of the Noteholders in respect of which it has been appointed.\\n\\nThe Representative of the Noteholders shall in any case be responsible for any loss incurred by the Issuer as a consequence any misconduct or default on the part of such delegate or sub delegate. The Representative of the Noteholders shall as soon as reasonably practicable give notice to the Issuer of the appointment of any delegate and the renewal, extension and termination of such appointment and shall procure that any delegate shall also as soon as reasonably practicable give notice to the Issuer of any sub delegate.\\n\\nThe Representative of the Noteholders shall act in accordance with the provisions of article 1176, second paragraph of the Italian civil code.\\n\\nThe Class A1 Noteholders, the Class A2 Noteholders, the Class B Noteholders and the Class J Noteholders recognise that the Representative of the Noteholders shall have all the necessary powers and authority to make all decisions, calculations and determinations, take all steps and actions, institute all legal proceedings, execute all agreements, instruments and documents which might be necessary or which it might deem advisable in connection with the issue of the Notes, and in particular (but not limited to) to execute and deliver the Transaction Documents to which respectively the holders of the Class A1 Notes, the Class A2 Notes, the Class B Notes and the Class J Notes are or will be a party. Each of the Class A1 Noteholders, the Class A2 Noteholders, the Class B Noteholders and the Class J Noteholders recognise, pursuant to article 1395 of the Italian civil code (contratto con se stesso), that the Representative of the Noteholders is authorized to deliver and execute any Transaction Documents to which it is and the holders of the Class A1 Notes, the Class A2 Notes, the Class B Notes or the Class J Notes, as the case may be, are parties.\\n\\nThe Representative of the Noteholders shall be authorised to represent the Organisation of Noteholders in judicial proceedings, including in proceedings involving the Issuer, creditors agreement (concordato preventivo), forced liquidation (fallimento) or compulsory administrative liquidation (liquidazione coatta amministrativa) or restructuring agreement (accordi di ristrutturazione dei debiti).\\n\\nArticle 27 (Resignation of the Representative of the Noteholders)', metadata={'source': 'data/input/prospectus.pdf', '_id': '16490454159943e09f0a6969457c48a5', '_collection_name': 'multiple-files'}),\n",
       " Document(page_content='In the event of the Representative of the Noteholders considering it expedient or necessary or being requested by the Issuer to undertake duties which the Representative of the Noteholders and the Issuer agree to be of an exceptional nature (in particular, following a Trigger Event) or otherwise outside the scope of the normal duties of the Representative of the Noteholders as contemplated in these Rules of the Organisation of the Noteholders, the Issuer shall pay to the Representative of the Noteholders such additional remuneration as shall be agreed between them. If the Representative of the Noteholders and the Issuer fail to agree upon whether such duties shall be of an exceptional nature or otherwise outside the scope of the normal duties of the Representative of the Noteholders as contemplated in these Rules of the Organisation of the Noteholders, or upon such additional remuneration, then such matter shall be determined (at the Issuers expense) by an investment bank (acting as an expert and not as an arbitrator) selected by the Representative of the Noteholders and approved by the Issuer or, failing such approval within thirty (30) calendar days, nominated (on the application of either the Issuer or the Representative of the Noteholders) by a third investment bank (the expenses involved in such nomination and the fees of such investment banks being payable by the Issuer) and the determination of any such investment bank shall be final and binding upon the Representative of the Noteholders and the Issuer.\\n\\nArticle 26 (Duties and Powers)\\n\\n147\\n\\nThe Representative of the Noteholders is the legal representative of the Organisation of Noteholders subject to and in accordance with the Conditions, these Rules, the Intercreditor Agreement and the other Transaction Documents to which it is a party (together, the Relevant Provisions).\\n\\nSubject to the Relevant Provisions, the Representative of the Noteholders is responsible for implementing the decisions of the Meeting and for protecting the Noteholders interests vis  vis the Issuer, in accordance with and following any resolution taken by the Meeting. The Representative of the Noteholders has the right to attend Meetings. The Representative of the Noteholders may convene a Meeting to obtain instructions from the Relevant Class Noteholders on any action to be taken.\\n\\nAll actions taken by the Representative of the Noteholders in the execution and exercise of all its powers and authorities and of discretion vested in it shall be taken by duly authorised officer(s) for the time being of the Representative of the Noteholders.', metadata={'source': 'data/input/prospectus.pdf', '_id': '682f89503ee0415e991980e2faa784bb', '_collection_name': 'multiple-files'}),\n",
       " Document(page_content='52\\n\\nSingle Portfolio Priority of Payment\\n\\nServicer under item Third) of the Pre Acceleration Order of Priority; and\\n\\n(ii)\\n\\nany amount that would otherwise have been payable under items from Seventh to Eighteenth of the Pre  Acceleration Order of Priority will not be included in the relevant Payments Report and shall remain in the Payments Account and become payable (together with the relevant Master Servicer Fees) in accordance with the applicable Order of Priority on the first following Payment Date on which the information contained in the missing Quarterly Servicer Report has been received by the Computation Agent.\\n\\nPrior to the service of a Trigger Notice, the Single Portfolio Available Funds shall be deemed to be applied on each Payment Date to register, for the Originators accounting purposes only, the following payments in the following order of priority (the \"Single Portfolio Priority of Payment\") (in each case, only if and to the extent that payments of a higher priority have been registered in full):\\n\\n(a)\\n\\nFirst, to register the payment (pari passu and pro rata to the extent of the respective amounts thereof) of the relevant Outstanding Notes Ratio of (a) all costs, taxes and expenses required to be paid in order to preserve the corporate existence of the Issuer or to maintain it in good standing or to comply with applicable legislation and regulations or to fulfil due and payable payment obligations of the Issuer towards third parties (not expressly included in any following item of this Order of Priority) incurred in relation to the Transaction, to the extent that such costs, taxes, expenses and payments are not met by using the amount standing to the credit of the Expenses Account, (b) all costs and taxes required to be paid to maintain the ratings of the Rated Notes and in connection with the registration and deposit of the Notes, or any notice to be given to the Noteholders or the other parties to the Transaction Documents;\\n\\n(b)\\n\\nSecond, to register the payment in the following order (a) the relevant Outstanding Notes Ratio of the fees, expenses and all other amounts due the Representative of the Noteholders and the Security Trustee, (b) into the Expenses Account the relevant Outstanding Notes Ratio of the amount (if any) necessary to ensure that the balance standing to the credit of the Expenses Account as at such Payment Date is equal to the Retention Amount;\\n\\nto\\n\\n(c)\\n\\nThird, to register the payment (pari passu and pro rata to the extent of the respective amounts thereof) of the relevant Outstanding Notes Ratio (i) of the fees, expenses and all other amounts due and payable to the Cash Manager, the Computation Agent, the Agent Bank, the Transaction Bank, the Principal Paying Agent, the EMIR Reporting Agent, the Corporate Services Provider, the Back Up Servicer and the Corporate Services Provider; (ii) of the Master Servicer Fees to the Master Servicer and the Servicing Fees to the Servicers; and (iii)\\n\\n53\\n\\n(d)\\n\\n(e)\\n\\n(f)\\n\\n(g)\\n\\n(h)\\n\\n(i)\\n\\n(j)\\n\\n(k)\\n\\nof the fees and costs due to the Back up Servicer as successor of the Servicers and/or the Master Servicer pursuant to clause 3.2 of the Back Up Servicing Agreement;', metadata={'source': 'data/input/prospectus.pdf', '_id': '0561fa87d66b41958e259e94573f9150', '_collection_name': 'multiple-files'})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "retriever.get_relevant_documents(\"What is the name of the rep that had the most sales order?  How many sales did he have?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Query Retriever\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    max_tokens=800,\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    model_kwargs={\"top_p\": 0, \"frequency_penalty\": 0, \"presence_penalty\": 0},\n",
    ")\n",
    "\n",
    "class QuestionList(BaseModel):\n",
    "    questions: List[str] = Field(description=\"List of alternative questions\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=QuestionList)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"count\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "    template=\"\"\"# System Role: Specialized assistant vector search optimization\n",
    "    \n",
    "As a specialized assistant, your task is to create {count} nuanced queries employing specific terminology to enhance vector similarity searches based on the initial user query.\n",
    "\n",
    "## USER QUESTION\n",
    "{question}\n",
    "\n",
    "## OUTPUT FORMAT\n",
    "{format_instructions}\n",
    "\"\"\",\n",
    ")\n",
    "\n",
    "prompt_and_model = prompt | llm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the query splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 13:53:51,021 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-03-27 13:53:51,028 - INFO - Which sales representative had the highest number of sales orders?\n",
      "2024-03-27 13:53:51,029 - INFO - How many sales orders were made by the top performing sales representative?\n",
      "2024-03-27 13:53:51,031 - INFO - Can you provide the name and total sales orders of the sales representative with the most successful performance?\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the name of the rep that had the most sales order?  How many sales did he have?\"\n",
    "\n",
    "output = prompt_and_model.invoke({\"question\": question, \"count\": 3})\n",
    "\n",
    "results = QuestionList.model_validate_json(output.content)\n",
    "\n",
    "for q in results.questions:\n",
    "    logger.info(q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 14:06:02,468 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "questions=['What are the different levels of priority in the Priority of Distributions?', 'Can you explain the waterfall scheme in the Priority of Distributions?', 'How does the Priority of Payment impact the distribution of funds?', 'What factors determine the Priority of Distributions in this prospectus?', 'Are there any specific rules or regulations governing the Priority of Distributions?']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "question = \"What is the Priority of Distributions(aka Priority of Payment or waterfall scheme) for this prospectus?\"\n",
    "\n",
    "output = prompt_and_model.invoke({\"question\": question, \"count\": 5})\n",
    "questions = QuestionList.model_validate_json(output.content)\n",
    "print(questions)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    max_tokens=2000,\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    model_kwargs={\"top_p\": 0, \"frequency_penalty\": 0, \"presence_penalty\": 0},\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and run Chain with query splitter, extractor, and contextual compression retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import concurrent.futures\n",
    "import json\n",
    "\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=retriever,\n",
    ")\n",
    "\n",
    "def get_relevant_documents(question):\n",
    "    return compression_retriever.get_relevant_documents(question)\n",
    "\n",
    "for q in questions.questions:\n",
    "    logger.info(f\"{question=}\")\n",
    "\n",
    "content = []\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    results = executor.map(get_relevant_documents, questions.questions)\n",
    "    content = list(results)\n",
    "\n",
    "all_data = list()\n",
    "ids = list()\n",
    "\n",
    "for c in content:\n",
    "    for e in c:\n",
    "        if e.metadata.get(\"doc_id\") in ids:\n",
    "            continue\n",
    "        ids.append(e.metadata.get(\"doc_id\"))\n",
    "        all_data.append(e.page_content)\n",
    "        \n",
    "prompt_template = \"\"\"# You are a sarcastic and egotistical financial analyst bot. Given the context, answer the user's question in an upbeat positive tone.\n",
    "\n",
    "## CONTEXT\n",
    "```\n",
    "{docs}\n",
    "```\n",
    "\n",
    "**User Question:** {question}\n",
    "\"\"\"\n",
    "\n",
    "print(f\"{len(all_data)=}\")\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"docs\", \"question\"],\n",
    "    # template=\"## Document Content\\n{docs}\\n\\n## User Query{question}\\n\\nProvide a well formatted response in markdown.\",\n",
    "    template=prompt_template,\n",
    "\n",
    ")\n",
    "\n",
    "llm2 = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    max_tokens=4000,\n",
    "    model_name=\"gpt-4-turbo-preview\",\n",
    "    model_kwargs={\"top_p\": 0, \"frequency_penalty\": 0, \"presence_penalty\": 0},\n",
    ")\n",
    "\n",
    "prompt_and_model2 = prompt | llm2\n",
    "results = prompt_and_model2.invoke({\"question\": question, \"docs\": json.dumps(all_data)})\n",
    "\n",
    "\n",
    "print(results.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
